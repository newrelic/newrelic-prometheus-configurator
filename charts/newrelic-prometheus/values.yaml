# -- Override the name of the chart
nameOverride: ""
# -- Override the full name of the release
fullnameOverride: ""

# -- Name of the Kubernetes cluster monitored. Can be configured also with `global.cluster`
cluster: ""
# -- This set this license key to use. Can be configured also with `global.licenseKey`
licenseKey: ""
# -- In case you don't want to have the license key in you values, this allows you to point to a user created secret to get the key from there. Can be configured also with `global.customSecretName`
customSecretName: ""
# -- In case you don't want to have the license key in you values, this allows you to point to which secret key is the license key located. Can be configured also with `global.customSecretLicenseKey`
customSecretLicenseKey: ""

images:
  # -- The secrets that are needed to pull images from a custom registry.
  pullSecrets: []

  configurator:
    registry: ""
    repository: newrelic/newrelic-prometheus-configurator
    pullPolicy: IfNotPresent
    tag: ""
  prometheus:
    registry: ""
    repository: quay.io/prometheus/prometheus
    pullPolicy: IfNotPresent
    tag: v2.36.2

# -- Settings controlling ServiceAccount creation.
# @default -- See `values.yaml`
serviceAccount:
  # -- Whether the chart should automatically create the ServiceAccount objects required to run.
  create: true
  annotations: {}
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Additional labels for chart objects. Can be configured also with `global.labels`
labels: {}
# -- Annotations to be added to all pods created by the integration.
podAnnotations: {}
# -- Additional labels for chart pods. Can be configured also with `global.podLabels`
podLabels: {}

# -- Sets pod's priorityClassName. Can be configured also with `global.priorityClassName`
priorityClassName: ""
# -- (bool) Sets pod's hostNetwork. Can be configured also with `global.hostNetwork`
# @default -- `false`
hostNetwork:
# -- Sets security context (at pod level). Can be configured also with `global.podSecurityContext`
podSecurityContext: {}
# -- Sets security context (at container level). Can be configured also with `global.containerSecurityContext`
containerSecurityContext: {}

# -- Sets pod's dnsConfig. Can be configured also with `global.dnsConfig`
dnsConfig: {}

# -- Settings controlling RBAC objects creation.
rbac:
  # -- Whether the chart should automatically create the RBAC objects required to run.
  create: true
  # -- Whether the chart should create Pod Security Policy objects.
  pspEnabled: false

# -- Sets pod/node affinities set almost globally. (See [Affinities and tolerations](README.md#affinities-and-tolerations))
affinity: {}
# -- Sets pod's node selector almost globally. (See [Affinities and tolerations](README.md#affinities-and-tolerations))
nodeSelector: {}
# -- Sets pod's tolerations to node taints almost globally. (See [Affinities and tolerations](README.md#affinities-and-tolerations))
tolerations: []

# -- (bool) Send the metrics to the staging backend. Requires a valid staging license key. Can be configured also with `global.nrStaging`
# @default -- `false`
nrStaging:

# -- (bool) Reduces number of metrics sent in order to reduce costs. Can be configured also with `global.lowDataMode`
# @default -- false
lowDataMode:

# -- New Relic prometheus configuration.
# TODO: we need to set default values only when those values are not the same than prometheus agent defaults'.
config:
  common:
#    The labels to add to any timeseries that this Prometheus instance scrapes.
#    external_labels:
#      one: two
#    How frequently to scrape targets by default.
    scrape_interval: 30s
#    The default timeout when scraping targets.
#    scrape_timeout: 10s

#  newrelic_remote_write:
#    extra_write_relabel_configs: []
#    proxy_url: ""
#    remote_timeout: 30s
#    # prometheus tls_config setup, see <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#tls_config> for details.
#    tls_config:
#    # queue_config setup, see prometheus remote-write tuning <https://prometheus.io/docs/practices/remote_write/#remote-write-tuning>
#    # for a more detailed explanation.
#    queue_config:
#       # Number of samples to buffer per shard before we block reading of more
#       # samples from the WAL. It is recommended to have enough capacity in each
#       # shard to buffer several requests to keep throughput up while processing
#       # occasional slow remote requests.
#       capacity: 2500
#       # Maximum number of shards, i.e. amount of concurrency.
#       max_shards: 200
#       # Minimum number of shards, i.e. amount of concurrency.
#       min_shards: 1
#       # Maximum number of samples per send.
#       max_samples_per_send: 500
#       # Maximum time a sample will wait in buffer.
#       batch_send_deadline: 5s
#       # Initial retry delay. Gets doubled for every retry.
#       min_backoff: 30ms
#       # Maximum retry delay.
#       max_backoff: 5s
#       # Retry upon receiving a 429 status code from the remote-write storage.
#       retry_on_http_429: false

#  extra_remote_write: []

#  # kubernetes jobs allow defining scrape jobs for kubernetes in a simple way.
  kubernetes:
    jobs:
    # By default all pods and endpoints with 'prometeus.io/scrape: true' annotation will be discovered.
    # The job_name_prefix is mandatory and no other job using the same prefix should be used in the whole configuration.
    - job_name_prefix: kubernetes-job
      # Target discovery field allows customizing how kubernetes discovery works.
      target_discovery:
        # -- Whether pods should be discovered.
        pod: true
        # -- Whether endpoints should be discovered.
        endpoints: true
        # -- Define filtering criteria, it is possible to set labels and/or annotations. All filters will apply (defined
        # filters are taken into account as an "and operation").
        filter:
          annotations:
            prometheus.io/scrape: true
          # labels: {}

#  for more info about static_targets: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
  static_targets:
    jobs:
#    # The job name assigned to scraped metrics by default.
#    - job_name: ""
#      # The targets specified for this job
#      targets: []
#      # Labels assigned to all metrics scraped from the targets.
#      labels: {}
#      # The HTTP resource path on which to fetch metrics from targets.
#      metrics_path: /metrics
#      # honor_labels controls how Prometheus handles conflicts between label,
#      # more info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
#      honor_labels: true
#      # honor_timestamps controls whether Prometheus respects the timestamps present n scraped data.
#      honor_timestamps: true
#      # Optional HTTP URL parameters.
#      params: {}
#      # Configures the protocol scheme used for requests.
#      scheme: "http"
#      # An uncompressed response body larger than this many bytes will cause the scrape to fail. 0 means no limit.
#      # Example: 100MB.
#      body_size_limit: 0
#      # Per-scrape limit on number of scraped samples that will be accepted. 0 means no limit.
#      sample_limit: 0
#      # Per-scrape config limit on number of unique targets that will be accepted. 0 means no limit.
#      target_limit: 0
#      # Per-scrape limit on number of labels that will be accepted for a sample. 0 means no limit.
#      label_limit: 0
#      # Per-scrape limit on length of labels name that will be accepted for a sample. 0 means no limit.
#      label_name_length_limit: 0
#      # Per-scrape limit on length of labels value that will be accepted for a sample. 0 means no limit
#      label_value_length_limit: 0
#      # How frequently to scrape targets from this job.
#      scrape_interval: 30s
#      # Per-scrape timeout when scraping this job.
#      scrape_timeout: 30s
#      # Configures the scrape request's TLS settings.
#      tls_config:
#      # Sets the `Authorization` header on every scrape request
#      authorization:
#      # List of target relabel configurations.
#      extra_relabel_config: []
#      # List of metric relabel configurations.
#      extra_metric_relabel_config: []
    # prometheus self-metrics job is always active reporting only the metrics on the regex list.
    - job_name: self-metrics
      targets:
        - "localhost:9090"
      extra_metric_relabel_config:
        - source_labels: [__name__]
          regex: "\
            prometheus_agent_active_series|\
            prometheus_target_interval_length_seconds|\
            prometheus_target_scrape_pool_targets|\
            prometheus_remote_storage_samples_pending|\
            prometheus_remote_storage_samples_in_total|\
            prometheus_remote_storage_samples_retried_total|\
            prometheus_agent_corruptions_total|\
            prometheus_remote_storage_shards|\
            prometheus_sd_kubernetes_events_total|\
            prometheus_agent_checkpoint_creations_failed_total|\
            prometheus_agent_checkpoint_deletions_failed_total|\
            prometheus_remote_storage_samples_dropped_total|\
            prometheus_remote_storage_samples_failed_total|\
            prometheus_sd_kubernetes_http_request_total|\
            prometheus_agent_truncate_duration_seconds_sum|\
            prometheus_build_info|\
            process_resident_memory_bytes|\
            process_virtual_memory_bytes|\
            process_cpu_seconds_total"
          action: keep
#  # extra scrape configs in prometheus format https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
#  extra_scrape_configs: {}
